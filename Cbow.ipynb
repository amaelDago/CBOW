{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0NPQzgPZq-M",
        "colab_type": "text"
      },
      "source": [
        "Data preparation for CBOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NlL7PCXHY9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "164a9f77-cdf2-4f52-bf7f-c9b56e69f13a"
      },
      "source": [
        "# Import librairies\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "from utils2 import *\n",
        "\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DATP9NEtaP40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define tokenize function\n",
        "\n",
        "def tokenize(sentence) : \n",
        "  \"\"\"\n",
        "  Tokenize a sentence\n",
        "  Input : \n",
        "    sentence : string\n",
        "  Output : \n",
        "    sentence : list of tokenized sentence\n",
        "  \"\"\"\n",
        "  sentence =  nltk.word_tokenize(re.sub(r'[,!?.]', '.', sentence), language = \"french\")\n",
        "  sentence_tokenized = [token.lower() for token in sentence\n",
        "              if token.isalpha()\n",
        "              or token == \".\"]\n",
        "\n",
        "  return sentence_tokenized\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEdsZg2pIVLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_windows(words, C) :\n",
        "  \"\"\"\n",
        "  For a word in words, give context word if possible\n",
        "  Input : \n",
        "    words : tokenized sentence\n",
        "    C : number of context word at left and at right\n",
        "  Output : \n",
        "    center a word and his context words\n",
        "  \n",
        "  \"\"\"\n",
        "  i = C\n",
        "\n",
        "  while i < len(words) - C : \n",
        "    center_word = words[i]\n",
        "    context_word = words[(i-C) : i] + words[(i + 1) : (i + C + 1) ]\n",
        "\n",
        "    yield center_word, context_word \n",
        "    i += 1\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5FLJbqBH4l8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b9fc85c-e219-4b7e-d975-86f8d5491df0"
      },
      "source": [
        "#Create function witch upload  a dataset and give word and in context for a given word.\n",
        "\n",
        "def upload_data(filename) : \n",
        "\n",
        "  \"\"\"\n",
        "  1 Import file\n",
        "  2 Read by line\n",
        "  3 tokenization\n",
        "  4 Storage in a list\n",
        "  \"\"\"\n",
        "  tokenize_l = []\n",
        "  # Import file\n",
        "  file = open(filename, 'r').read()\n",
        "  # Split by \"\\n\"\n",
        "  file = file.split(\"\\n\")\n",
        "\n",
        "  # Loop for tokenizing sentence\n",
        "  for line in file : \n",
        "    tokenized_line = tokenize(line)\n",
        "    if tokenized_line : \n",
        "      tokenize_l.extend(tokenize(line))\n",
        "  return tokenize_l\n",
        "\n",
        "# Upload text\n",
        "f = upload_data(\"test.txt\")\n",
        "\n",
        "print(f[:10])\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['numberly', 'aide', 'ses', 'clients', 'à', 'collecter', '.', 'analyser', 'et', 'mettre']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfUbD_05idIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f28d6c2d-cc0b-4844-c807-ea0d4784ffc4"
      },
      "source": [
        "# Create a vocabulary\n",
        "# Create a dictionary where keys are word and value its index\n",
        "# Create a dictionary where keys are index and value its word\n",
        "\n",
        "def get_dict(corpus) : \n",
        "  \"\"\"\n",
        "  1 create a temporary liste of unique words in a corpus\n",
        "  2 give a number to each word\n",
        "  3 create the 2 dictionary\n",
        "  Input : corpus like a list of tokenized sentence\n",
        "  Output : \n",
        "    word2ind : dictionary which have word in key and indice of word in value \n",
        "    ind2word : dictionary which have indice in key and word in value\n",
        "    vocabulary : a list of unique words\n",
        "  \"\"\"\n",
        "\n",
        "  vocab = sorted(set(corpus))\n",
        "  # word2ind\n",
        "  word2ind = {word : i for i, word in enumerate(vocab)}\n",
        "  # ind2word\n",
        "  ind2word = {i : word for i, word in enumerate(vocab)}\n",
        "\n",
        "  return word2ind, ind2word\n",
        "\n",
        "word2ind, ind2word = get_dict(f)\n",
        "print(len(word2ind), len(ind2word))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "642 642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFQAt708ocB1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get one-hot vector from words\n",
        "\n",
        "def get_one_hot_vector(word, word2ind, size) : \n",
        "  \"\"\"\n",
        "  Input : \n",
        "    context_words : list of context words\n",
        "    word2ind : dictionary which have word in key and indice of word in value\n",
        "    size = dimension of word embedding\n",
        "  Output : \n",
        "    one hot vector \n",
        "  \"\"\"\n",
        "  # Initialize matrix\n",
        "  vec = np.zeros(size)\n",
        "  \n",
        "  if word in word2ind.keys() : \n",
        "    vec[word2ind[word]] = 1\n",
        "   \n",
        "  return(vec)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnKKNoknrko6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get context vectors\n",
        "def get_context_vectors(context_words, word2ind, size) : \n",
        "  \"\"\"\n",
        "  Input : \n",
        "    context_words : list of context words\n",
        "    word2ind : dictionary which have word in key and indice of word in value\n",
        "    size = dimension of word embedding\n",
        "  Output : \n",
        "    context vector \n",
        "  \"\"\"\n",
        "  return np.mean([get_one_hot_vector(word, word2ind, size) for word in context_words], axis = 0)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JohefQlZtK_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_example(words, word2ind,  size, C = 2) :\n",
        "  \"\"\"\n",
        "  For words give for each center word, its one hot and its context vectors\n",
        "  \"\"\"\n",
        "\n",
        "  for center_word, context_words in get_windows(words, C) : \n",
        "    \n",
        "    yield get_one_hot_vector(center_word, word2ind, size), get_context_vectors(context_words, word2ind, size)\n",
        "  "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4hxFWMXo4Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We have our 2 sets for computing CBOW. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PaRFSjs3ZyA",
        "colab_type": "text"
      },
      "source": [
        "Continuous Bag of Word Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjsoLZ38bG3h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2783db2f-2b25-4b4e-b8ca-76e373482264"
      },
      "source": [
        "# Definition of functions used for modelisation\n",
        "\n",
        "def relu(z) : \n",
        "  if type(z) != np.ndarray :\n",
        "    z = np.array(z)\n",
        "  z[z<0] = 0\n",
        "  return z\n",
        "\n",
        "def softmax(z) : \n",
        "  if type(z) != np.ndarray :\n",
        "   z = np.array(z)\n",
        "  exp_z = np.exp(z)\n",
        "  sum_exp_z = np.sum(exp_z)\n",
        "  return exp_z/sum_exp_z\n",
        "\n",
        "# Test softmax function\n",
        "softmax([-4, 1,4])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.19450938e-04, 4.74107229e-02, 9.52269826e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSHDvY9fbjjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize model\n",
        "\n",
        "def initialize_model(N, V, random_seed = 0): \n",
        "  \"\"\" \n",
        "  Input : \n",
        "      N : size of hidden layer\n",
        "      V : length of vocabulary\n",
        "  Output : \n",
        "    W : dictionary of Weights W1 and W2\n",
        "    b : dictionary of biais b1 and b2\n",
        "  \"\"\"\n",
        "  # Set seed\n",
        "  np.random.seed(random_seed)\n",
        "\n",
        "  # Initialize W1\n",
        "  W1 = np.random.rand(N*V).reshape(N,V)\n",
        "  \n",
        "  # Initialize b1\n",
        "  b1 = np.random.rand(N).reshape(N,-1)\n",
        "  \n",
        "  # Initialize W2\n",
        "  W2 = np.random.rand(N*V).reshape(V,N)\n",
        "\n",
        "  # Initialize 2 \n",
        "  b2 = np.random.rand(V).reshape(V,-1)\n",
        "\n",
        "  return W1, W2, b1, b2\n"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HJ9QsQP1OEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def forward_prop(x, W1, W2, b1, b2):\n",
        "    '''\n",
        "    Inputs: \n",
        "        x:  average one hot vector for the context \n",
        "        W1, W2, b1, b2:  matrices and biases to be learned\n",
        "     Outputs: \n",
        "        z:  output score vector\n",
        "    '''\n",
        "    \n",
        "    ### START CODE HERE (Replace instances of 'None' with your own code) ###\n",
        "    \n",
        "    # Calculate h\n",
        "    h = np.dot(W1, x) + b1\n",
        "    \n",
        "    # Apply the relu on h (store result in h)\n",
        "    h = relu(h)\n",
        "    \n",
        "    # Calculate z\n",
        "    z = np.dot(W2, h) + b2\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    return z, h"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGTZ-d2G3CYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Back propagation\n",
        "\n",
        "def back_prop(x, y_hat, y, h, W1, W2, b1, b2, batch_size) :\n",
        "\n",
        "  '''\n",
        "  Inputs: \n",
        "      x:  average one hot vector for the context \n",
        "      yhat: prediction (estimate of y)\n",
        "      y:  target vector\n",
        "      h:  hidden vector (see eq. 1)\n",
        "      W1, W2, b1, b2:  matrices and biases  \n",
        "      batch_size: batch size \n",
        "    Outputs: \n",
        "      grad_W1, grad_W2, grad_b1, grad_b2:  gradients of matrices and biases   \n",
        "  '''\n",
        "\n",
        "  l1 = relu(np.dot(W2.T, (y_hat - y)))\n",
        "\n",
        "  # Compute the gradient of W1\n",
        "  grad_W1 = np.dot(l1, x.T)\n",
        "\n",
        "  # Compute the gradient of W2\n",
        "  grad_W2 = np.dot((y_hat - y), h.T)\n",
        "\n",
        "  # Compute the gradient of b1\n",
        "  grad_b1 = np.sum(l1, axis = 1, keepdims=True)/batch_size\n",
        "  \n",
        "  # Compute the gradient of b2\n",
        "  grad_b2 = np.sum((y_hat - y), axis = 1, keepdims = True)/batch_size\n",
        "\n",
        "  return W1, W2, b1, b2"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HSuFUWMFfow",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9634dd42-02b9-4d31-af02-28d7d07c76b3"
      },
      "source": [
        "# compute_cost: cross-entropy cost functioN\n",
        "def compute_cost(y, yhat, batch_size):\n",
        "    # cost function \n",
        "    logprobs = np.multiply(np.log(yhat),y) + np.multiply(np.log(1 - yhat), 1 - y)\n",
        "    cost = - 1/batch_size * np.sum(logprobs)\n",
        "    cost = np.squeeze(cost)\n",
        "    return cost\n",
        "  \n",
        "# Cross entropy\n",
        "def cross_entropy_loss(y_hat, y):\n",
        "\n",
        "  loss = np.sum(-np.log(y_hat)*y)/len(y)\n",
        "\n",
        "  return loss\n",
        "cross_entropy_loss(y_hat, y)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5122282727130949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT0jM49kKMD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def gradient_descent(data, word2Ind, N, V, num_iters, alpha=0.03):\n",
        "    \n",
        "  '''\n",
        "  This is the gradient_descent function\n",
        "  \n",
        "    Inputs: \n",
        "      data:      text\n",
        "      word2Ind:  words to Indices\n",
        "      N:         dimension of hidden vector  \n",
        "      V:         dimension of vocabulary \n",
        "      num_iters: number of iterations  \n",
        "    Outputs: \n",
        "      W1, W2, b1, b2:  updated matrices and biases   \n",
        "\n",
        "  '''\n",
        "  W1, W2, b1, b2 = initialize_model(N,V, random_seed=282)\n",
        "  batch_size = 128\n",
        "  iters = 0\n",
        "  C = 2\n",
        "  for x, y in get_batches(data, word2Ind, V, C, batch_size):\n",
        "\n",
        "      # Get z and h\n",
        "      z, h = forward_prop(x, W1, W2, b1, b2)\n",
        "\n",
        "      # Get yhat\n",
        "      yhat = softmax(z)\n",
        "\n",
        "      # Get cost\n",
        "      cost = compute_cost(y, yhat, batch_size)\n",
        "      if ( (iters+1) % 10 == 0):\n",
        "          print(f\"iters: {iters + 1} cost: {cost:.6f}\")\n",
        "          \n",
        "      # Get gradients\n",
        "      grad_W1, grad_W2, grad_b1, grad_b2 = back_prop(x, yhat, y, h, W1, W2, b1, b2, batch_size)\n",
        "      \n",
        "      # Update weights and biases\n",
        "      W1 = W1 - alpha * grad_W1 \n",
        "      W2 = W2 - alpha * grad_W2\n",
        "      b1 = b1 - alpha * grad_b1\n",
        "      b2 = b2 - alpha * grad_b2\n",
        "      \n",
        "      ### END CODE HERE ###\n",
        "      \n",
        "      iters += 1 \n",
        "      if iters == num_iters: \n",
        "          break\n",
        "      if iters % 100 == 0:\n",
        "          alpha *= 0.66\n",
        "          \n",
        "  return W1, W2, b1, b2"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzZbWPZcDoEd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "8ca7fbb9-dda0-4603-bbf7-7905bb2dcd40"
      },
      "source": [
        "# test your function\n",
        "C = 2\n",
        "N = 50\n",
        "word2Ind, Ind2word = get_dict(f)\n",
        "V = len(word2Ind)\n",
        "print(V)\n",
        "num_iters = 150\n",
        "print(\"Call gradient_descent\")\n",
        "W1, W2, b1, b2 = gradient_descent(f, word2Ind, N, V, num_iters)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "642\n",
            "Call gradient_descent\n",
            "iters: 10 cost: 11.485822\n",
            "iters: 20 cost: 11.279810\n",
            "iters: 30 cost: 11.279304\n",
            "iters: 40 cost: 11.308265\n",
            "iters: 50 cost: 11.329036\n",
            "iters: 60 cost: 11.338994\n",
            "iters: 70 cost: 11.341899\n",
            "iters: 80 cost: 11.341168\n",
            "iters: 90 cost: 11.338929\n",
            "iters: 100 cost: 11.336311\n",
            "iters: 110 cost: 11.334573\n",
            "iters: 120 cost: 11.333063\n",
            "iters: 130 cost: 11.331718\n",
            "iters: 140 cost: 11.330544\n",
            "iters: 150 cost: 11.329533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz09MjGI6jpi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "16d82c02-0f2f-4a70-80ea-08b18d6da85c"
      },
      "source": [
        "# We can get word embedding from columns of matrix of weights W1. For example the embedding of word to the first indices is : \n",
        "indice = 1\n",
        "print(ind2word[indice])\n",
        "print()\n",
        "print(\"The embedding of word {} are {}\".format(ind2word[indice], W1[:,indice]))\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acceptez\n",
            "\n",
            "The embedding of word acceptez are [6.85309413e-03 4.65330243e-03 1.63023251e-02 1.58029527e-02\n",
            " 1.67314198e-02 1.07483169e-03 1.20410305e-02 8.04831063e-03\n",
            " 5.80444443e-03 9.67911222e-03 5.84495617e-03 5.66849971e-03\n",
            " 1.08434593e-04 3.73289452e-03 1.71801527e-02 6.34377197e-03\n",
            " 7.01554319e-03 5.41482484e-03 6.72697130e-03 1.52933243e-02\n",
            " 2.92263535e-05 7.36884986e-03 2.70631899e-03 1.28997728e-02\n",
            " 8.48618531e-03 1.02672019e-02 3.99995310e-03 1.30955728e-02\n",
            " 1.66801730e-03 5.18420649e-03 7.43941159e-03 1.67910675e-02\n",
            " 5.31569609e-03 1.08203418e-02 3.75455248e-03 9.97789582e-03\n",
            " 1.37296948e-03 1.30139092e-02 1.52450247e-02 1.20977102e-02\n",
            " 1.05900308e-02 1.62972130e-02 1.64352611e-03 4.00535765e-03\n",
            " 2.86697444e-03 2.06723759e-03 1.29749405e-03 1.55095156e-02\n",
            " 1.65617317e-02 6.88603653e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Sx9joVy1lO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_pca(data, n_components=2):\n",
        "    \"\"\"\n",
        "    Input: \n",
        "        data: of dimension (m,n) where each row corresponds to a word vector\n",
        "        n_components: Number of components you want to keep.\n",
        "    Output: \n",
        "        X_reduced: data transformed in 2 dims/columns + regenerated original data\n",
        "    pass in: data as 2D NumPy array\n",
        "    \"\"\"\n",
        "\n",
        "    m, n = data.shape\n",
        "\n",
        "    # mean center the data\n",
        "    data -= data.mean(axis=0)\n",
        "\n",
        "    # calculate the covariance matrix\n",
        "    R = np.cov(data, rowvar=False)\n",
        "\n",
        "    # calculate eigenvectors & eigenvalues of the covariance matrix\n",
        "    evals, evecs = linalg.eigh(R)\n",
        "\n",
        "    # sort eigenvalue in decreasing order\n",
        "    # this returns the corresponding indices of evals and evecs\n",
        "    idx = np.argsort(evals)[::-1]\n",
        "    evecs = evecs[:, idx]\n",
        "    \n",
        "    # sort eigenvectors according to same index\n",
        "    evals = evals[idx]\n",
        "\n",
        "    # select the first n eigenvectors \n",
        "    evecs = evecs[:, :n_components]\n",
        "\n",
        "    return np.dot(evecs.T, data.T).T"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP8feXFp4jx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "eb850c3c-496e-4198-bde3-4feb44349d4b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "names = tokenize(\"data scientists temps réel marketing visualisation stage ou alternance Vous avez niveau expérience deep learning machine\")\n",
        "indices = [word2ind[word] for word in names]\n",
        "\n",
        "X = W1[:,indices]\n",
        "\n",
        "result= compute_pca(X.T, 2)\n",
        "plt.scatter(result[:, 0], result[:, 1])\n",
        "for i, word in enumerate(names):\n",
        "    plt.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
        "plt.show()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}